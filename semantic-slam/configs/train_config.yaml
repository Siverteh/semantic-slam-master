# Training Configuration with Proper Train/Val/Test Split
# NO OVERLAP between train/val/test!

# Model architecture
model:
  backbone: "vit_small_patch16_dinov3.lvd1689m"
  input_size: 448
  num_keypoints: 500

  selector_hidden: 256
  selector_layers: 3

  descriptor_dim: 128
  refiner_hidden: 384  # Increased capacity
  refiner_layers: 4

  estimator_hidden: 128

# Dataset configuration - PROPER SPLIT!
dataset:
  root: "data/tum_rgbd"

  # TRAINING: 3 sequences (mix of easy/medium, static)
  train_sequences:
    - "rgbd_dataset_freiburg1_desk"   # Easy: Static office, lots of texture
    - "rgbd_dataset_freiburg1_room"   # Medium: Room with varied textures
    - "rgbd_dataset_freiburg3_walking_static"  # Challenge: Dynamic person (fr3 sensor)

  # VALIDATION: 1 sequence (main challenge case)
  val_sequences:
    - "rgbd_dataset_freiburg1_plant"  # Hard: Low texture (classic SLAM challenge)

  # TEST (for final evaluation only): 2 sequences - NEVER SEEN DURING TRAINING!
  # Note: These should ONLY be used in test scripts, not during training
  test_sequences:
    - "rgbd_dataset_freiburg3_long_office_household"  # Long sequence, drift test
    - "rgbd_dataset_freiburg3_walking_xyz"  # Dynamic + structured motion

  frame_spacing: 1
  max_frames: null

  # Data augmentation
  augmentation:
    enabled: true
    brightness: 0.2
    contrast: 0.2
    hue: 0.1
    saturation: 0.2
    gaussian_blur: 0.3

# Loss configuration - CORRECT APPROACH!
loss:
  weights:
    desc: 8.0        # Strong descriptor learning (dominant)
    repeat: 0.3
    variance: 0.5    # Prevent collapse
    peakiness: 0.1
    activation: 0.05
    edge: 0.3        # REDUCED from 0.8! (was too dominant)
    sparsity: 0.3

  # Descriptor loss (InfoNCE)
  desc_temperature: 0.10  # Slightly higher for stability
  desc_negatives: 40

  # Repeatability loss
  repeat_threshold: 2.0

  # Peakiness loss
  target_variance: 0.22

  # Activation loss
  sparsity_target: 0.35

  # Edge awareness loss
  edge_threshold: 0.1

  # Spatial sparsity loss
  sparsity_penalty: 2.0

# Training configuration
training:
  epochs: 60
  batch_size: 4
  lr: 1e-4
  lr_min: 1e-6
  weight_decay: 1e-4
  grad_clip: 1.0
  num_workers: 4
  warmup_epochs: 3

  val_interval: 1
  save_interval: 5
  save_dir: "checkpoints"

# Logging configuration
logging:
  use_wandb: true
  project: "semantic-slam-thesis"
  run_name: "proper-split-fixed-edge-v1"
  log_interval: 50

# Dataset rationale (for your thesis documentation):
#
# TRAINING (3 sequences):
#   - fr1_desk: Baseline static scene with good texture
#   - fr1_room: More complex indoor environment
#   - fr3_walking_static: Introduces dynamic objects + fr3 sensor diversity
#
# VALIDATION (1 sequence):
#   - fr1_plant: Low-texture challenge (standard SLAM benchmark)
#
# TEST (2 sequences - use ONLY for final evaluation):
#   - fr3_long_office_household: Tests long-term stability and drift
#   - fr3_walking_xyz: Tests dynamic scene handling
#
# This split ensures:
#   1. No train/test overlap (prevents overfitting)
#   2. Sensor diversity (fr1 Kinect v1 + fr3 Kinect v2)
#   3. Challenge diversity (static, low-texture, dynamic, long-term)
#   4. Standard benchmarks (fr1_plant, fr1_desk are widely used)